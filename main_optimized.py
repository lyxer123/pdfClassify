#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PDF Pattern Recognition - Optimized Standard Document Feature Extraction
åŸºäºmb5.pngçš„ä¼˜åŒ–ç‰ˆæœ¬ï¼ŒåŒ…å«åŒºåŸŸåˆ†æã€ç•™ç™½æ¯”ä¾‹ç»Ÿè®¡ã€æ–‡å­—è¯†åˆ«ç­‰åŠŸèƒ½
"""

import cv2
import numpy as np
from PIL import Image
import re
from typing import Dict, List, Tuple, Optional
import os
import pytesseract

class OptimizedStandardDocumentFeatureExtractor:
    """
    ä¼˜åŒ–ç‰ˆæ ‡å‡†æ–‡æ¡£ç‰¹å¾æŠ½å–å™¨ï¼ˆåŸºäºmb5.pngï¼‰
    
    åŠŸèƒ½ç‰¹ç‚¹ï¼š
    1. åŸºäºmb5.pngçš„3ä¸ªè“è‰²æ¡†è¿›è¡ŒåŒºåŸŸåˆ†æï¼ˆä¸Šéƒ¨ã€ä¸­éƒ¨ã€ä¸‹éƒ¨ï¼‰
    2. ç»Ÿè®¡å„åŒºåŸŸç•™ç™½æ¯”ä¾‹ä½œä¸ºåˆ¤æ–­ä¾æ®
    3. ä¸Šéƒ¨å’Œä¸‹éƒ¨æ–‡å­—è¯†åˆ«ï¼ˆåŒ…å«"æ ‡å‡†"å’Œ"å‘å¸ƒ"ï¼‰
    4. ç»“åˆmb4.pngçš„æ–‡å­—åˆ†å¸ƒç‰¹å¾
    """
    
    def __init__(self, image_path: str):
        """
        åˆå§‹åŒ–æŠ½å–å™¨
        
        Args:
            image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        """
        self.image_path = image_path
        self.image = None
        self.gray_image = None
        self.features = {}
        
        # åŒºåŸŸå®šä¹‰ï¼ˆåŸºäºmb5.pngçš„è“è‰²æ¡†ï¼‰
        self.regions = {
            'upper': {'y_start': 0, 'y_end': 0.3, 'name': 'ä¸Šéƒ¨'},
            'middle': {'y_start': 0.3, 'y_end': 0.7, 'name': 'ä¸­éƒ¨'},
            'lower': {'y_start': 0.7, 'y_end': 1.0, 'name': 'ä¸‹éƒ¨'}
        }
        
    def load_image(self) -> bool:
        """
        åŠ è½½å›¾ç‰‡
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ è½½
        """
        try:
            self.image = cv2.imread(self.image_path)
            if self.image is None:
                print(f"æ— æ³•åŠ è½½å›¾ç‰‡: {self.image_path}")
                return False
                
            self.gray_image = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)
            print(f"æˆåŠŸåŠ è½½å›¾ç‰‡: {self.image_path}")
            print(f"å›¾ç‰‡å°ºå¯¸: {self.image.shape}")
            return True
        except Exception as e:
            print(f"åŠ è½½å›¾ç‰‡æ—¶å‡ºé”™: {e}")
            return False
    
    def detect_blue_boxes(self) -> Dict:
        """
        æ£€æµ‹è“è‰²æ¡†åŒºåŸŸï¼ˆåŸºäºmb5.pngçš„æ ‡æ³¨ï¼‰
        
        Returns:
            Dict: æ£€æµ‹åˆ°çš„è“è‰²æ¡†åŒºåŸŸ
        """
        try:
            # è½¬æ¢åˆ°HSVè‰²å½©ç©ºé—´
            hsv = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)
            
            # å®šä¹‰è“è‰²èŒƒå›´
            lower_blue = np.array([100, 50, 50])
            upper_blue = np.array([130, 255, 255])
            
            # åˆ›å»ºè“è‰²æ©ç 
            blue_mask = cv2.inRange(hsv, lower_blue, upper_blue)
            
            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            blue_boxes = []
            for contour in contours:
                x, y, w, h = cv2.boundingRect(contour)
                area = w * h
                
                # è¿‡æ»¤å¤ªå°çš„åŒºåŸŸ
                if area > 1000:  # æœ€å°é¢ç§¯é˜ˆå€¼
                    blue_boxes.append({
                        'x': x, 'y': y, 'w': w, 'h': h,
                        'area': area,
                        'center_y': y + h // 2
                    })
            
            # æŒ‰yåæ ‡æ’åºï¼Œç¡®å®šä¸Šä¸­ä¸‹åŒºåŸŸ
            blue_boxes.sort(key=lambda x: x['center_y'])
            
            detected_regions = {}
            if len(blue_boxes) >= 3:
                detected_regions['upper'] = blue_boxes[0]
                detected_regions['middle'] = blue_boxes[1]
                detected_regions['lower'] = blue_boxes[2]
            else:
                # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°è¶³å¤Ÿçš„è“è‰²æ¡†ï¼Œä½¿ç”¨é»˜è®¤åŒºåŸŸ
                height = self.image.shape[0]
                detected_regions = {
                    'upper': {'y': 0, 'h': int(height * 0.3)},
                    'middle': {'y': int(height * 0.3), 'h': int(height * 0.4)},
                    'lower': {'y': int(height * 0.7), 'h': int(height * 0.3)}
                }
            
            return detected_regions
            
        except Exception as e:
            print(f"æ£€æµ‹è“è‰²æ¡†æ—¶å‡ºé”™: {e}")
            # è¿”å›é»˜è®¤åŒºåŸŸ
            height = self.image.shape[0]
            return {
                'upper': {'y': 0, 'h': int(height * 0.3)},
                'middle': {'y': int(height * 0.3), 'h': int(height * 0.4)},
                'lower': {'y': int(height * 0.7), 'h': int(height * 0.3)}
            }
    
    def calculate_whitespace_ratio(self, region: Dict) -> float:
        """
        è®¡ç®—åŒºåŸŸç•™ç™½æ¯”ä¾‹
        
        Args:
            region: åŒºåŸŸä¿¡æ¯
            
        Returns:
            float: ç•™ç™½æ¯”ä¾‹ (0-1)
        """
        try:
            y_start = region['y']
            y_end = region['y'] + region['h']
            x_start = 0
            x_end = self.image.shape[1]
            
            # æå–åŒºåŸŸ
            region_image = self.gray_image[y_start:y_end, x_start:x_end]
            
            # äºŒå€¼åŒ–
            _, binary = cv2.threshold(region_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # è®¡ç®—ç™½è‰²åƒç´ æ¯”ä¾‹ï¼ˆç•™ç™½ï¼‰
            total_pixels = binary.shape[0] * binary.shape[1]
            white_pixels = np.sum(binary == 255)
            whitespace_ratio = white_pixels / total_pixels
            
            return whitespace_ratio
            
        except Exception as e:
            print(f"è®¡ç®—ç•™ç™½æ¯”ä¾‹æ—¶å‡ºé”™: {e}")
            return 0.5  # é»˜è®¤å€¼
    
    def extract_text_from_region(self, region: Dict) -> str:
        """
        ä»åŒºåŸŸæå–æ–‡å­—
        
        Args:
            region: åŒºåŸŸä¿¡æ¯
            
        Returns:
            str: æå–çš„æ–‡å­—
        """
        try:
            y_start = region['y']
            y_end = region['y'] + region['h']
            x_start = 0
            x_end = self.image.shape[1]
            
            # æå–åŒºåŸŸ
            region_image = self.image[y_start:y_end, x_start:x_end]
            
            # é¢„å¤„ç†
            gray_region = cv2.cvtColor(region_image, cv2.COLOR_BGR2GRAY)
            
            # ä½¿ç”¨OCRæå–æ–‡å­—
            text = pytesseract.image_to_string(gray_region, lang='chi_sim+eng')
            
            return text.strip()
            
        except Exception as e:
            print(f"æ–‡å­—æå–æ—¶å‡ºé”™: {e}")
            return ""
    
    def check_keywords(self, text: str, keywords: List[str]) -> bool:
        """
        æ£€æŸ¥æ–‡å­—ä¸­æ˜¯å¦åŒ…å«å…³é”®è¯
        
        Args:
            text: æ–‡å­—å†…å®¹
            keywords: å…³é”®è¯åˆ—è¡¨
            
        Returns:
            bool: æ˜¯å¦åŒ…å«å…³é”®è¯
        """
        text_lower = text.lower()
        for keyword in keywords:
            if keyword in text_lower:
                return True
        return False
    
    def analyze_regions(self) -> Dict:
        """
        åˆ†æä¸‰ä¸ªåŒºåŸŸ
        
        Returns:
            Dict: åŒºåŸŸåˆ†æç»“æœ
        """
        # æ£€æµ‹è“è‰²æ¡†
        blue_regions = self.detect_blue_boxes()
        
        analysis_results = {}
        
        for region_name, region_info in blue_regions.items():
            # è®¡ç®—ç•™ç™½æ¯”ä¾‹
            whitespace_ratio = self.calculate_whitespace_ratio(region_info)
            
            # æå–æ–‡å­—
            text = self.extract_text_from_region(region_info)
            
            # æ£€æŸ¥å…³é”®è¯
            if region_name == 'upper':
                has_keywords = self.check_keywords(text, ['æ ‡å‡†'])
            elif region_name == 'lower':
                has_keywords = self.check_keywords(text, ['å‘å¸ƒ'])
            else:
                has_keywords = True  # ä¸­éƒ¨ä¸æ£€æŸ¥ç‰¹å®šå…³é”®è¯
            
            analysis_results[region_name] = {
                'whitespace_ratio': whitespace_ratio,
                'text': text,
                'has_keywords': has_keywords,
                'region_info': region_info
            }
        
        return analysis_results
    
    def detect_red_boxes(self, region: Dict) -> List[Dict]:
        """
        æ£€æµ‹çº¢è‰²æ¡†ï¼ˆåœ¨è“è‰²æ¡†å†…ï¼‰
        
        Args:
            region: è“è‰²æ¡†åŒºåŸŸä¿¡æ¯
            
        Returns:
            List[Dict]: çº¢è‰²æ¡†åˆ—è¡¨
        """
        try:
            y_start = region['y']
            y_end = region['y'] + region['h']
            x_start = 0
            x_end = self.image.shape[1]
            
            # æå–åŒºåŸŸ
            region_image = self.image[y_start:y_end, x_start:x_end]
            
            # è½¬æ¢åˆ°HSVè‰²å½©ç©ºé—´
            hsv = cv2.cvtColor(region_image, cv2.COLOR_BGR2HSV)
            
            # å®šä¹‰çº¢è‰²èŒƒå›´
            lower_red1 = np.array([0, 50, 50])
            upper_red1 = np.array([10, 255, 255])
            lower_red2 = np.array([170, 50, 50])
            upper_red2 = np.array([180, 255, 255])
            
            # åˆ›å»ºçº¢è‰²æ©ç 
            red_mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
            red_mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
            red_mask = cv2.bitwise_or(red_mask1, red_mask2)
            
            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            red_boxes = []
            for contour in contours:
                x, y, w, h = cv2.boundingRect(contour)
                area = w * h
                
                # è¿‡æ»¤å¤ªå°çš„åŒºåŸŸ
                if area > 100:  # æœ€å°é¢ç§¯é˜ˆå€¼
                    red_boxes.append({
                        'x': x, 'y': y, 'w': w, 'h': h,
                        'area': area
                    })
            
            return red_boxes
            
        except Exception as e:
            print(f"æ£€æµ‹çº¢è‰²æ¡†æ—¶å‡ºé”™: {e}")
            return []
    
    def compare_with_mb4(self) -> float:
        """
        ä¸mb4.pngè¿›è¡Œæ¯”å¯¹
        
        Returns:
            float: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
        """
        try:
            if not os.path.exists("mb4.png"):
                print("mb4.pngæ–‡ä»¶ä¸å­˜åœ¨")
                return 0.0
            
            # åŠ è½½mb4.png
            mb4_image = cv2.imread("mb4.png")
            if mb4_image is None:
                print("æ— æ³•åŠ è½½mb4.png")
                return 0.0
            
            # è½¬æ¢ä¸ºç°åº¦å›¾
            mb4_gray = cv2.cvtColor(mb4_image, cv2.COLOR_BGR2GRAY)
            image_gray = cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY)
            
            # è°ƒæ•´å¤§å°ä»¥è¿›è¡Œæ¯”è¾ƒ
            height, width = image_gray.shape
            mb4_resized = cv2.resize(mb4_gray, (width, height))
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = cv2.matchTemplate(image_gray, mb4_resized, cv2.TM_CCOEFF_NORMED)
            max_similarity = np.max(similarity)
            
            return max_similarity
            
        except Exception as e:
            print(f"ä¸mb4.pngæ¯”å¯¹æ—¶å‡ºé”™: {e}")
            return 0.0
    
    def extract_features(self) -> Dict:
        """
        æå–æ‰€æœ‰ç‰¹å¾
        
        Returns:
            Dict: ç‰¹å¾æå–ç»“æœ
        """
        if not self.load_image():
            return {'error': 'æ— æ³•åŠ è½½å›¾ç‰‡'}
        
        # åˆ†æåŒºåŸŸ
        region_analysis = self.analyze_regions()
        
        # ä¸mb4.pngæ¯”å¯¹
        mb4_similarity = self.compare_with_mb4()
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        scores = []
        
        # ä¸Šéƒ¨è¯„åˆ†
        upper_score = 0.0
        if region_analysis['upper']['has_keywords']:
            upper_score += 0.4
        if 0.3 <= region_analysis['upper']['whitespace_ratio'] <= 0.7:
            upper_score += 0.3
        else:
            upper_score += 0.1
        scores.append(upper_score)
        
        # ä¸­éƒ¨è¯„åˆ†
        middle_score = 0.0
        if 0.2 <= region_analysis['middle']['whitespace_ratio'] <= 0.6:
            middle_score += 0.5
        else:
            middle_score += 0.2
        scores.append(middle_score)
        
        # ä¸‹éƒ¨è¯„åˆ†
        lower_score = 0.0
        if region_analysis['lower']['has_keywords']:
            lower_score += 0.4
        if 0.3 <= region_analysis['lower']['whitespace_ratio'] <= 0.7:
            lower_score += 0.3
        else:
            lower_score += 0.1
        scores.append(lower_score)
        
        # ç»¼åˆè¯„åˆ†
        overall_score = sum(scores) / len(scores)
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºæ ‡å‡†æ–‡æ¡£
        is_standard_document = (
            region_analysis['upper']['has_keywords'] and
            region_analysis['lower']['has_keywords'] and
            overall_score >= 0.6 and
            mb4_similarity >= 0.3
        )
        
        return {
            'is_standard_document': is_standard_document,
            'overall_score': overall_score,
            'mb4_similarity': mb4_similarity,
            'region_analysis': region_analysis,
            'scores': {
                'upper': scores[0],
                'middle': scores[1],
                'lower': scores[2]
            }
        }
    
    def print_analysis(self):
        """
        æ‰“å°åˆ†æç»“æœ
        """
        result = self.extract_features()
        
        if 'error' in result:
            print(f"é”™è¯¯: {result['error']}")
            return
        
        print(f"\n{'='*50}")
        print("ä¼˜åŒ–ç‰ˆæ ‡å‡†æ–‡æ¡£åˆ†æç»“æœ")
        print(f"{'='*50}")
        
        print(f"\nğŸ“‹ æ€»ä½“åˆ¤æ–­:")
        status = "âœ… æ˜¯æ ‡å‡†æ–‡æ¡£" if result['is_standard_document'] else "âŒ ä¸æ˜¯æ ‡å‡†æ–‡æ¡£"
        print(f"  {status}")
        print(f"  ç»¼åˆè¯„åˆ†: {result['overall_score']:.3f}")
        print(f"  mb4ç›¸ä¼¼åº¦: {result['mb4_similarity']:.3f}")
        
        print(f"\nğŸ“Š åŒºåŸŸåˆ†æ:")
        for region_name, analysis in result['region_analysis'].items():
            region_name_cn = {'upper': 'ä¸Šéƒ¨', 'middle': 'ä¸­éƒ¨', 'lower': 'ä¸‹éƒ¨'}[region_name]
            print(f"\n  {region_name_cn}:")
            print(f"    ç•™ç™½æ¯”ä¾‹: {analysis['whitespace_ratio']:.3f}")
            print(f"    å…³é”®è¯æ£€æµ‹: {'âœ…' if analysis['has_keywords'] else 'âŒ'}")
            print(f"    åŒºåŸŸè¯„åˆ†: {result['scores'][region_name]:.3f}")
            if analysis['text'].strip():
                print(f"    æå–æ–‡å­—: {analysis['text'][:50]}...")
        
        print(f"\n{'='*50}")

def main():
    """
    ä¸»å‡½æ•° - æµ‹è¯•ä¼˜åŒ–ç‰ˆç‰¹å¾æå–
    """
    import sys
    
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python main_optimized.py <image_path>")
        return
    
    image_path = sys.argv[1]
    
    extractor = OptimizedStandardDocumentFeatureExtractor(image_path)
    extractor.print_analysis()

if __name__ == "__main__":
    main()

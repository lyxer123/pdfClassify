#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ä¿®æ­£åçš„ç¬¬äºŒç‰¹å¾æ£€æµ‹ç®—æ³•
"""

import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
# å¯¼å…¥æµ‹è¯•åŒ…é…ç½®
from tests import PROJECT_ROOT, TEMPLATES_DIR, DATA_DIR
from pdf_feature_extractor import PDFFeatureExtractor
import logging

# å¯ç”¨DEBUGæ—¥å¿—
logging.basicConfig(level=logging.DEBUG, format='%(levelname)s: %(message)s')

def test_corrected_detection():
    """æµ‹è¯•ä¿®æ­£åçš„è¿é€šç»„ä»¶åˆ†ææ–¹æ³•"""
    
    # åŠ è½½æ¨¡æ¿å›¾ç‰‡
    template_img = np.array(Image.open(str(TEMPLATES_DIR / 'mb.png').convert('RGB'))
    print(f"å›¾ç‰‡å°ºå¯¸: {template_img.shape}")
    
    extractor = PDFFeatureExtractor()
    
    print("\nğŸ” ä½¿ç”¨ä¿®æ­£åçš„æ–¹æ³•æ£€æµ‹ç¬¬äºŒç‰¹å¾...")
    print("æœŸæœ›æ£€æµ‹åˆ°ä¸¤æ¡çº¿:")
    print("  çº¿æ¡1: yâ‰ˆ359 (25%é«˜åº¦), å®½åº¦â‰ˆ306 (30%)")
    print("  çº¿æ¡2: yâ‰ˆ1245 (86.7%é«˜åº¦), å®½åº¦â‰ˆ826 (81%)")
    
    result = extractor.detect_mb_second_feature(template_img)
    
    print(f"\næ£€æµ‹ç»“æœ:")
    print(f"  æ˜¯å¦æœ‰ç¬¬äºŒç‰¹å¾: {result['has_second_feature']}")
    print(f"  æ£€æµ‹åˆ°çš„é•¿æ¨ªçº¿æ•°é‡: {result['detected_lines']}")
    
    if result['has_second_feature']:
        long_lines = result['long_lines']
        print(f"  æ£€æµ‹åˆ°çš„é•¿æ¨ªçº¿:")
        for i, line in enumerate(long_lines):
            y_pos = line['y_center']
            length = line['length']
            y_percent = y_pos / template_img.shape[0] * 100
            length_percent = length / template_img.shape[1] * 100
            print(f"    çº¿æ¡{i+1}: y={y_pos:.0f} ({y_percent:.1f}%é«˜åº¦), é•¿åº¦={length:.0f} ({length_percent:.1f}%å®½åº¦)")
        
        line_distance = result['line_distance']
        distance_percent = line_distance / template_img.shape[0] * 100
        print(f"  ä¸¤çº¿é—´è·: {line_distance:.0f}åƒç´  ({distance_percent:.1f}%é«˜åº¦)")
        
        # éªŒè¯æ£€æµ‹å‡†ç¡®æ€§
        expected_y1, expected_y2 = 359, 1245
        actual_y1 = long_lines[0]['y_center']
        actual_y2 = long_lines[1]['y_center'] if len(long_lines) > 1 else 0
        
        error_y1 = abs(actual_y1 - expected_y1)
        error_y2 = abs(actual_y2 - expected_y2) if len(long_lines) > 1 else float('inf')
        
        print(f"\nå‡†ç¡®æ€§éªŒè¯:")
        print(f"  ç¬¬ä¸€æ¡çº¿: æœŸæœ›y={expected_y1}, å®é™…y={actual_y1:.0f}, è¯¯å·®={error_y1:.0f}åƒç´ ")
        if len(long_lines) > 1:
            print(f"  ç¬¬äºŒæ¡çº¿: æœŸæœ›y={expected_y2}, å®é™…y={actual_y2:.0f}, è¯¯å·®={error_y2:.0f}åƒç´ ")
        
        accuracy_ok = error_y1 <= 10 and error_y2 <= 50  # å…è®¸ä¸€å®šè¯¯å·®
        print(f"  æ£€æµ‹å‡†ç¡®æ€§: {'âœ“ é€šè¿‡' if accuracy_ok else 'âŒ ä¸å‡†ç¡®'}")
        
        # åˆ›å»ºå¯è§†åŒ–
        create_corrected_visualization(template_img, result, expected_y1, expected_y2)
        
    else:
        print(f"  å¤±è´¥åŸå› : {result['reason']}")
    
    return result['has_second_feature']

def create_corrected_visualization(image, result, expected_y1, expected_y2):
    """åˆ›å»ºä¿®æ­£åçš„å¯è§†åŒ–å›¾åƒ"""
    
    pil_image = Image.fromarray(image)
    draw = ImageDraw.Draw(pil_image)
    
    try:
        font = ImageFont.truetype("arial.ttf", 14)
        small_font = ImageFont.truetype("arial.ttf", 10)
    except:
        font = ImageFont.load_default()
        small_font = ImageFont.load_default()
    
    height, width = image.shape[:2]
    
    # ç»˜åˆ¶æœŸæœ›ä½ç½®ï¼ˆé»„è‰²è™šçº¿ï¼‰
    draw.line([(0, expected_y1), (width, expected_y1)], fill='yellow', width=2)
    draw.line([(0, expected_y2), (width, expected_y2)], fill='yellow', width=2)
    draw.text((10, expected_y1-20), f"æœŸæœ›çº¿æ¡1: y={expected_y1}", fill='yellow', font=small_font)
    draw.text((10, expected_y2-20), f"æœŸæœ›çº¿æ¡2: y={expected_y2}", fill='yellow', font=small_font)
    
    if result['has_second_feature']:
        long_lines = result['long_lines']
        
        for i, line in enumerate(long_lines):
            coords = line['coords']
            x1, y1, x2, y2 = int(coords[0]), int(coords[1]), int(coords[2]), int(coords[3])
            
            # ç»˜åˆ¶çº¢è‰²æ£€æµ‹ç»“æœ
            draw.line([(x1, y1), (x2, y2)], fill='red', width=4)
            
            # æ·»åŠ æ ‡ç­¾
            y_pos = line['y_center']
            length = line['length']
            y_percent = y_pos / height * 100
            length_percent = length / width * 100
            
            label = f"æ£€æµ‹çº¿æ¡{i+1}: y={y_pos:.0f}({y_percent:.1f}%) L={length_percent:.0f}%"
            label_x = int((x1 + x2) / 2) - 100
            label_y = int(y_pos) + 15
            
            draw.text((label_x, label_y), label, fill='red', font=font)
        
        # æ·»åŠ ç»“æœä¿¡æ¯
        line_distance = result['line_distance']
        distance_percent = line_distance / height * 100
        info_text = f"ä¿®æ­£åæ£€æµ‹ç»“æœ: {len(long_lines)}æ¡é•¿æ¨ªçº¿\né—´è·: {line_distance:.0f}px ({distance_percent:.1f}%é«˜åº¦)\né»„è‰²=æœŸæœ›ä½ç½®ï¼Œçº¢è‰²=æ£€æµ‹ç»“æœ"
        draw.text((10, 10), info_text, fill='black', font=font)
    
    # ä¿å­˜ç»“æœ
    output_path = "hengxian_corrected.png"
    pil_image.save(output_path)
    print(f"\nâœ“ ä¿®æ­£åçš„å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {output_path}")

if __name__ == "__main__":
    success = test_corrected_detection()
    if success:
        print("\nğŸ‰ ä¿®æ­£åçš„æ£€æµ‹æ–¹æ³•æˆåŠŸï¼")
    else:
        print("\nâŒ ä¿®æ­£åçš„æ£€æµ‹æ–¹æ³•ä»æœ‰é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒæ•´")

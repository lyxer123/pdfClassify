#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡æ£€æµ‹ F:\æ ‡å‡†è§„èŒƒè¦æ±‚\å……ç”µ ç›®å½•ä¸‹PDFæ–‡ä»¶çš„é•¿é»‘æ¨ªçº¿
"""

import os
import fitz  # PyMuPDF
import cv2
import numpy as np
from PIL import Image
from pathlib import Path
# å¯¼å…¥æµ‹è¯•åŒ…é…ç½®
from tests import PROJECT_ROOT, TEMPLATES_DIR, DATA_DIR
from pdf_feature_extractor import PDFFeatureExtractor
import logging
import json
from datetime import datetime

# è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºINFOï¼Œå‡å°‘DEBUGä¿¡æ¯
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

def batch_detect_charging_pdfs():
    """æ‰¹é‡æ£€æµ‹å……ç”µç›®å½•ä¸‹çš„PDFæ–‡ä»¶"""
    
    charging_dir = r"F:\æ ‡å‡†è§„èŒƒè¦æ±‚\å……ç”µ"
    
    print(f"æ‰«æç›®å½•: {charging_dir}")
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(charging_dir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {charging_dir}")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰PDFæ–‡ä»¶
    pdf_files = []
    for root, dirs, files in os.walk(charging_dir):
        for file in files:
            if file.lower().endswith('.pdf'):
                pdf_path = os.path.join(root, file)
                pdf_files.append(pdf_path)
    
    print(f"æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
    
    if len(pdf_files) == 0:
        print("âŒ æœªæ‰¾åˆ°PDFæ–‡ä»¶")
        return
    
    # åˆå§‹åŒ–ç‰¹å¾æå–å™¨
    extractor = PDFFeatureExtractor()
    
    # ç»Ÿè®¡ç»“æœ
    results = []
    success_count = 0
    total_pages = 0
    
    print(f"\nå¼€å§‹æ‰¹é‡æ£€æµ‹...")
    print(f"{'='*80}")
    
    for i, pdf_path in enumerate(pdf_files):
        print(f"\nå¤„ç†ç¬¬ {i+1}/{len(pdf_files)} ä¸ªæ–‡ä»¶:")
        print(f"æ–‡ä»¶: {os.path.basename(pdf_path)}")
        
        try:
            # æ‰“å¼€PDFæ–‡ä»¶
            doc = fitz.open(pdf_path)
            pages_with_feature = []
            
            # æ£€æµ‹æ¯ä¸€é¡µ
            for page_num in range(len(doc)):
                try:
                    page = doc.load_page(page_num)
                    
                    # è½¬æ¢ä¸ºå›¾åƒ
                    mat = fitz.Matrix(2.0, 2.0)  # 2å€ç¼©æ”¾æé«˜è´¨é‡
                    pix = page.get_pixmap(matrix=mat)
                    img_data = pix.tobytes("ppm")
                    
                    # è½¬æ¢ä¸ºnumpyæ•°ç»„
                    nparr = np.frombuffer(img_data, np.uint8)
                    image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                    
                    # æ£€æµ‹ç¬¬äºŒç‰¹å¾
                    result = extractor.detect_mb_second_feature(image_rgb)
                    
                    total_pages += 1
                    
                    if result['has_second_feature']:
                        success_count += 1
                        pages_with_feature.append({
                            'page': page_num + 1,
                            'lines': result['long_lines'],
                            'distance': result['line_distance'],
                            'distance_ratio': result['line_distance_ratio']
                        })
                        print(f"  ğŸ“„ ç¬¬{page_num + 1}é¡µ: âœ… æ£€æµ‹åˆ°2æ¡é•¿é»‘æ¨ªçº¿")
                        
                        # æ˜¾ç¤ºçº¿æ¡ä¿¡æ¯
                        for j, line in enumerate(result['long_lines']):
                            y_pos = line['y_center']
                            length_percent = line['width_ratio'] * 100
                            y_percent = y_pos / image_rgb.shape[0] * 100
                            print(f"    çº¿æ¡{j+1}: y={y_pos:.0f}({y_percent:.1f}%), é•¿åº¦={length_percent:.1f}%å®½åº¦")
                        
                        distance_percent = result['line_distance_ratio'] * 100
                        print(f"    é—´è·: {result['line_distance']:.0f}åƒç´  ({distance_percent:.1f}%é«˜åº¦)")
                    
                except Exception as e:
                    print(f"  âŒ ç¬¬{page_num + 1}é¡µå¤„ç†å¤±è´¥: {str(e)}")
                    continue
            
            # è®°å½•æ–‡ä»¶ç»“æœ
            file_result = {
                'file_path': pdf_path,
                'file_name': os.path.basename(pdf_path),
                'total_pages': len(doc),
                'pages_with_feature': len(pages_with_feature),
                'success_pages': pages_with_feature,
                'success_rate': len(pages_with_feature) / len(doc) * 100 if len(doc) > 0 else 0
            }
            results.append(file_result)
            
            if pages_with_feature:
                print(f"âœ… æ–‡ä»¶æ€»ç»“: {len(pages_with_feature)}/{len(doc)} é¡µç¬¦åˆç¬¬äºŒç‰¹å¾ ({file_result['success_rate']:.1f}%)")
            else:
                print(f"âŒ æ–‡ä»¶æ€»ç»“: 0/{len(doc)} é¡µç¬¦åˆç¬¬äºŒç‰¹å¾")
            
            doc.close()
            
        except Exception as e:
            print(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            continue
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print(f"\n{'='*80}")
    print(f"æ‰¹é‡æ£€æµ‹å®Œæˆ!")
    print(f"{'='*80}")
    
    print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"  å¤„ç†æ–‡ä»¶æ•°: {len(pdf_files)}")
    print(f"  æ€»é¡µæ•°: {total_pages}")
    print(f"  æˆåŠŸé¡µæ•°: {success_count}")
    print(f"  æˆåŠŸç‡: {success_count/total_pages*100:.1f}%" if total_pages > 0 else "  æˆåŠŸç‡: 0%")
    
    # æŒ‰æˆåŠŸé¡µæ•°æ’åºæ˜¾ç¤ºæ–‡ä»¶ç»“æœ
    results.sort(key=lambda x: x['pages_with_feature'], reverse=True)
    
    print(f"\nğŸ“‹ æ–‡ä»¶æ£€æµ‹ç»“æœ (æŒ‰æˆåŠŸé¡µæ•°æ’åº):")
    print(f"{'åºå·':<4} {'æ–‡ä»¶å':<40} {'æˆåŠŸé¡µæ•°':<8} {'æ€»é¡µæ•°':<6} {'æˆåŠŸç‡':<8}")
    print(f"{'-'*4} {'-'*40} {'-'*8} {'-'*6} {'-'*8}")
    
    for i, result in enumerate(results):
        file_name = result['file_name']
        if len(file_name) > 37:
            file_name = file_name[:34] + "..."
        
        print(f"{i+1:<4} {file_name:<40} {result['pages_with_feature']:<8} {result['total_pages']:<6} {result['success_rate']:<7.1f}%")
    
    # æ˜¾ç¤ºæœ‰æˆåŠŸæ£€æµ‹çš„æ–‡ä»¶è¯¦æƒ…
    successful_files = [r for r in results if r['pages_with_feature'] > 0]
    
    if successful_files:
        print(f"\nğŸ‰ æœ‰æˆåŠŸæ£€æµ‹çš„æ–‡ä»¶è¯¦æƒ…:")
        for result in successful_files:
            print(f"\nğŸ“ {result['file_name']}:")
            print(f"   æ€»é¡µæ•°: {result['total_pages']}, æˆåŠŸé¡µæ•°: {result['pages_with_feature']}")
            for page_info in result['success_pages']:
                print(f"   ç¬¬{page_info['page']}é¡µ: é—´è·{page_info['distance']:.0f}åƒç´  ({page_info['distance_ratio']*100:.1f}%é«˜åº¦)")
    else:
        print(f"\nâŒ æ²¡æœ‰æ–‡ä»¶æ£€æµ‹åˆ°ç¬¦åˆç¬¬äºŒç‰¹å¾çš„é¡µé¢")
    
    # ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSONæ–‡ä»¶
    # ç¡®ä¿tests/dataç›®å½•å­˜åœ¨
    data_dir = Path(__file__).parent.parent / "data"
    data_dir.mkdir(parents=True, exist_ok=True)
    
    output_file = data_dir / f"charging_pdfs_detection_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    # å‡†å¤‡JSONæ•°æ®ï¼ˆå»é™¤ä¸èƒ½åºåˆ—åŒ–çš„numpyç±»å‹ï¼‰
    json_results = []
    for result in results:
        json_result = {
            'file_path': result['file_path'],
            'file_name': result['file_name'],
            'total_pages': result['total_pages'],
            'pages_with_feature': result['pages_with_feature'],
            'success_rate': result['success_rate'],
            'success_pages': []
        }
        
        for page_info in result['success_pages']:
            json_page = {
                'page': page_info['page'],
                'distance': float(page_info['distance']),
                'distance_ratio': float(page_info['distance_ratio']),
                'lines': []
            }
            
            for line in page_info['lines']:
                json_line = {
                    'y_center': float(line['y_center']),
                    'length': int(line['length']),
                    'width_ratio': float(line['width_ratio']),
                    'y_percent': float(line['y_center']) / 1000 * 100  # è¿‘ä¼¼è®¡ç®—
                }
                json_page['lines'].append(json_line)
            
            json_result['success_pages'].append(json_page)
        
        json_results.append(json_result)
    
    # ä¿å­˜ç»“æœ
    summary_data = {
        'scan_time': datetime.now().isoformat(),
        'source_directory': charging_dir,
        'total_files': len(pdf_files),
        'total_pages': total_pages,
        'successful_pages': success_count,
        'success_rate': success_count/total_pages*100 if total_pages > 0 else 0,
        'files': json_results
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(summary_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    return results

if __name__ == "__main__":
    print("æ‰¹é‡æ£€æµ‹å……ç”µç›®å½•ä¸‹PDFæ–‡ä»¶çš„é•¿é»‘æ¨ªçº¿")
    results = batch_detect_charging_pdfs()

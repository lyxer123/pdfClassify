#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æmb88.pngä¸­æ ‡æ³¨çš„æ­£ç¡®é•¿æ¨ªçº¿ä½ç½®
"""

import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import logging

# å¯ç”¨DEBUGæ—¥å¿—
logging.basicConfig(level=logging.DEBUG, format='%(levelname)s: %(message)s')

def analyze_red_lines_in_mb88():
    """åˆ†æmb88.pngä¸­çš„çº¢è‰²é•¿æ¨ªçº¿æ ‡æ³¨"""
    
    # åŠ è½½åŸå§‹å›¾ç‰‡å’Œæ ‡æ³¨å›¾ç‰‡
    original_img = np.array(Image.open('templates/mb.png').convert('RGB'))
    annotated_img = np.array(Image.open('templates/mb88.png').convert('RGB'))
    
    print(f"åŸå§‹å›¾ç‰‡å°ºå¯¸: {original_img.shape}")
    print(f"æ ‡æ³¨å›¾ç‰‡å°ºå¯¸: {annotated_img.shape}")
    
    height, width = original_img.shape[:2]
    
    # æ£€æµ‹çº¢è‰²åŒºåŸŸï¼ˆçº¢è‰²æ ‡æ³¨çº¿ï¼‰
    # çº¢è‰²åƒç´ ï¼šRå€¼é«˜ï¼ŒGå’ŒBå€¼ä½
    red_mask = (annotated_img[:, :, 0] > 200) & (annotated_img[:, :, 1] < 100) & (annotated_img[:, :, 2] < 100)
    
    print(f"çº¢è‰²åƒç´ æ•°é‡: {np.sum(red_mask)}")
    
    if np.sum(red_mask) == 0:
        print("âŒ æ²¡æœ‰æ£€æµ‹åˆ°çº¢è‰²æ ‡æ³¨")
        return
    
    # ä½¿ç”¨è¿é€šç»„ä»¶åˆ†ææ¥è¯†åˆ«çº¢è‰²çº¿æ¡
    result = cv2.connectedComponents(red_mask.astype(np.uint8))
    if isinstance(result, tuple) and len(result) == 2:
        num_labels, labels = result
    else:
        print("connectedComponentsè¿”å›æ ¼å¼å¼‚å¸¸")
        return
    
    print(f"çº¢è‰²è¿é€šç»„ä»¶æ•°é‡: {num_labels-1}")
    
    # åˆ†ææ¯ä¸ªçº¢è‰²è¿é€šç»„ä»¶
    red_lines = []
    
    for label in range(1, num_labels):
        component_mask = (labels == label)
        
        # è®¡ç®—è¿é€šç»„ä»¶çš„è¾¹ç•Œæ¡†
        y_coords, x_coords = np.where(component_mask)
        if len(y_coords) == 0:
            continue
            
        min_y, max_y = int(y_coords.min()), int(y_coords.max())
        min_x, max_x = int(x_coords.min()), int(x_coords.max())
        
        component_width = max_x - min_x + 1
        component_height = max_y - min_y + 1
        component_area = int(np.sum(component_mask))
        
        # è®¡ç®—ç‰¹å¾
        width_ratio = float(component_width) / float(width)
        aspect_ratio = float(component_width) / float(max(component_height, 1))
        y_center = float(min_y + max_y) / 2.0
        y_percent = y_center / float(height) * 100.0
        
        # åªè€ƒè™‘è¾ƒé•¿çš„çº¢è‰²åŒºåŸŸä½œä¸ºçº¿æ¡æ ‡æ³¨
        if component_width >= width * 0.3:  # è‡³å°‘30%å®½åº¦
            red_lines.append({
                'y_center': y_center,
                'y_percent': y_percent,
                'width': component_width,
                'height': component_height,
                'width_ratio': width_ratio,
                'aspect_ratio': aspect_ratio,
                'bbox': (min_x, min_y, max_x, max_y),
                'area': component_area
            })
            
            print(f"çº¢è‰²çº¿æ¡{len(red_lines)}: y={y_center:.0f}({y_percent:.1f}%), å®½åº¦={component_width}({width_ratio:.1%}), é«˜åº¦={component_height}, å®½é«˜æ¯”={aspect_ratio:.1f}")
    
    # æŒ‰yåæ ‡æ’åº
    red_lines.sort(key=lambda x: x['y_center'])
    
    print(f"\næ£€æµ‹åˆ° {len(red_lines)} æ¡çº¢è‰²æ ‡æ³¨çº¿:")
    for i, line in enumerate(red_lines):
        print(f"  çº¿æ¡{i+1}: y={line['y_center']:.0f} ({line['y_percent']:.1f}%é«˜åº¦), å®½åº¦={line['width']} ({line['width_ratio']:.1%})")
    
    # åˆ†æåŸå§‹å›¾ç‰‡åœ¨è¿™äº›ä½ç½®çš„é»‘è‰²å†…å®¹
    print(f"\nåˆ†æåŸå§‹å›¾ç‰‡åœ¨çº¢è‰²æ ‡æ³¨ä½ç½®çš„é»‘è‰²å†…å®¹:")
    
    original_gray = cv2.cvtColor(original_img, cv2.COLOR_RGB2GRAY)
    black_mask_original = original_gray < 80
    
    correct_black_lines = []
    
    for i, red_line in enumerate(red_lines):
        y_center = red_line['y_center']
        bbox = red_line['bbox']
        min_x, min_y, max_x, max_y = bbox
        
        # åœ¨çº¢è‰²æ ‡æ³¨åŒºåŸŸæŸ¥æ‰¾é»‘è‰²åƒç´ 
        roi_black = black_mask_original[min_y:max_y+1, min_x:max_x+1]
        black_pixel_count = np.sum(roi_black)
        
        if black_pixel_count > 0:
            # åœ¨ROIä¸­æ‰¾åˆ°é»‘è‰²åƒç´ çš„ç²¾ç¡®ä½ç½®
            roi_y_coords, roi_x_coords = np.where(roi_black)
            if len(roi_y_coords) > 0:
                # è½¬æ¢å›å…¨å›¾åæ ‡
                global_y_coords = roi_y_coords + min_y
                global_x_coords = roi_x_coords + min_x
                
                actual_min_y = int(global_y_coords.min())
                actual_max_y = int(global_y_coords.max())
                actual_min_x = int(global_x_coords.min())
                actual_max_x = int(global_x_coords.max())
                
                actual_width = actual_max_x - actual_min_x + 1
                actual_height = actual_max_y - actual_min_y + 1
                actual_y_center = float(actual_min_y + actual_max_y) / 2.0
                actual_y_percent = actual_y_center / float(height) * 100.0
                actual_width_ratio = float(actual_width) / float(width)
                
                correct_black_lines.append({
                    'y_center': actual_y_center,
                    'y_percent': actual_y_percent,
                    'width': actual_width,
                    'height': actual_height,
                    'width_ratio': actual_width_ratio,
                    'bbox': (actual_min_x, actual_min_y, actual_max_x, actual_max_y),
                    'pixel_count': black_pixel_count
                })
                
                print(f"  å¯¹åº”é»‘è‰²çº¿æ¡{i+1}: y={actual_y_center:.0f}({actual_y_percent:.1f}%), å®½åº¦={actual_width}({actual_width_ratio:.1%}), é«˜åº¦={actual_height}, é»‘è‰²åƒç´ ={black_pixel_count}")
        else:
            print(f"  çº¢è‰²æ ‡æ³¨åŒºåŸŸ{i+1}ä¸­æ²¡æœ‰æ‰¾åˆ°é»‘è‰²åƒç´ ")
    
    # ç”Ÿæˆæ–°çš„åˆ¤æ–­æ ‡å‡†
    if len(correct_black_lines) >= 2:
        print(f"\nåŸºäºæ ‡æ³¨çš„æ–°åˆ¤æ–­æ ‡å‡†å»ºè®®:")
        
        min_y_center = min(line['y_center'] for line in correct_black_lines)
        max_y_center = max(line['y_center'] for line in correct_black_lines)
        min_width = min(line['width'] for line in correct_black_lines)
        max_height = max(line['height'] for line in correct_black_lines)
        min_width_ratio = min(line['width_ratio'] for line in correct_black_lines)
        
        distance_between = max_y_center - min_y_center
        distance_percent = distance_between / float(height) * 100.0
        
        print(f"  ä¸¤æ¡çº¿yä½ç½®: {min_y_center:.0f} å’Œ {max_y_center:.0f}")
        print(f"  ä¸¤æ¡çº¿é—´è·: {distance_between:.0f}åƒç´  ({distance_percent:.1f}%é«˜åº¦)")
        print(f"  æœ€å°å®½åº¦: {min_width} ({min_width_ratio:.1%})")
        print(f"  æœ€å¤§é«˜åº¦: {max_height}")
        
        print(f"\nå»ºè®®çš„é•¿æ¨ªçº¿æ£€æµ‹æ ‡å‡†:")
        print(f"  1. å®½åº¦è‡³å°‘: {min_width_ratio*0.8:.1%} (å½“å‰æœ€å°å®½åº¦çš„80%)")
        print(f"  2. é«˜åº¦æœ€å¤š: {max_height + 10} åƒç´ ")
        print(f"  3. ä¸¤çº¿é—´è·è‡³å°‘: {distance_percent*0.5:.1f}% é«˜åº¦")
        print(f"  4. yä½ç½®èŒƒå›´: {min_y_center/height*100:.1f}% - {max_y_center/height*100:.1f}% é«˜åº¦")
    
    return correct_black_lines

def create_analysis_visualization(correct_lines):
    """åˆ›å»ºåˆ†æå¯è§†åŒ–å›¾åƒ"""
    
    original_img = np.array(Image.open('templates/mb.png').convert('RGB'))
    pil_image = Image.fromarray(original_img)
    draw = ImageDraw.Draw(pil_image)
    
    try:
        font = ImageFont.truetype("arial.ttf", 14)
    except:
        font = ImageFont.load_default()
    
    # ç»˜åˆ¶æ£€æµ‹åˆ°çš„æ­£ç¡®é»‘è‰²çº¿æ¡
    for i, line in enumerate(correct_lines):
        bbox = line['bbox']
        min_x, min_y, max_x, max_y = bbox
        
        # ç»˜åˆ¶ç»¿è‰²è¾¹ç•Œæ¡†è¡¨ç¤ºæ­£ç¡®çš„é»‘è‰²çº¿æ¡ä½ç½®
        draw.rectangle([min_x, min_y, max_x, max_y], outline='green', width=4)
        
        # æ·»åŠ æ ‡ç­¾
        y_percent = line['y_percent']
        width_ratio = line['width_ratio']
        label_text = f"æ­£ç¡®çº¿æ¡{i+1}: y={line['y_center']:.0f}({y_percent:.1f}%) W={width_ratio:.1%}"
        draw.text((min_x, min_y-20), label_text, fill='green', font=font)
    
    # æ·»åŠ ä¿¡æ¯
    if len(correct_lines) >= 2:
        distance = abs(correct_lines[1]['y_center'] - correct_lines[0]['y_center'])
        distance_percent = distance / original_img.shape[0] * 100
        info_text = f"æ­£ç¡®çš„ä¸¤æ¡é•¿æ¨ªçº¿ä½ç½®\né—´è·: {distance:.0f}px ({distance_percent:.1f}%é«˜åº¦)"
        draw.text((10, 10), info_text, fill='green', font=font)
    
    # ä¿å­˜å›¾åƒ
    output_path = "correct_lines_analysis.png"
    pil_image.save(output_path)
    print(f"\nâœ“ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_path}")

if __name__ == "__main__":
    print("ğŸ” åˆ†æmb88.pngä¸­çš„çº¢è‰²æ ‡æ³¨çº¿...")
    correct_lines = analyze_red_lines_in_mb88()
    
    if correct_lines:
        create_analysis_visualization(correct_lines)
        print("\nğŸ‰ åˆ†æå®Œæˆï¼è¯·æŸ¥çœ‹ç”Ÿæˆçš„æ–°åˆ¤æ–­æ ‡å‡†å»ºè®®ã€‚")
    else:
        print("\nâŒ åˆ†æå¤±è´¥ï¼Œæ— æ³•ç¡®å®šæ­£ç¡®çš„é•¿æ¨ªçº¿ä½ç½®ã€‚")
